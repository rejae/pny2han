{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文件统计："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['aishell_test.txt',\n",
       " 'chunks.txt',\n",
       " 'aishell_dev.txt',\n",
       " 'stcmd.txt',\n",
       " 'aishell_train.txt',\n",
       " 'aidatatang.txt',\n",
       " 'prime.txt',\n",
       " 'thchs_train.txt',\n",
       " 'thchs_test.txt',\n",
       " 'thchs_dev.txt',\n",
       " 'trans.txt']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "path = './'\n",
    "#os.chdir(path)\n",
    "import re\n",
    "\n",
    "\n",
    "filenames= os.listdir()\n",
    "file_list = [ filename  for filename in filenames if filename.endswith('.txt') and filename.islower()]\n",
    "print('total:',len(file_list))\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chunks.txt',\n",
       " 'aishell_dev.txt',\n",
       " 'stcmd.txt',\n",
       " 'aishell_train.txt',\n",
       " 'aidatatang.txt',\n",
       " 'prime.txt',\n",
       " 'thchs_train.txt',\n",
       " 'thchs_test.txt',\n",
       " 'thchs_dev.txt',\n",
       " 'trans.txt']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 规范数据格式校验代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 18290.90it/s]\n",
      "  0%|          | 0/14326 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunks.txt\n",
      "119\n",
      "aishell_dev.txt\n",
      "14326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14326/14326 [00:00<00:00, 21443.91it/s]\n",
      "  0%|          | 0/102600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stcmd.txt\n",
      "102600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102600/102600 [00:03<00:00, 26252.10it/s]\n",
      "  0%|          | 0/120098 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aishell_train.txt\n",
      "120098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120098/120098 [00:05<00:00, 22381.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aidatatang.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 3250/237265 [00:00<00:07, 32492.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237265/237265 [00:08<00:00, 28810.04it/s]\n",
      "  0%|          | 0/50902 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prime.txt\n",
      "50902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50902/50902 [00:03<00:00, 14456.61it/s]\n",
      " 12%|█▏        | 1161/10000 [00:00<00:00, 11602.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thchs_train.txt\n",
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 10335.80it/s]\n",
      " 43%|████▎     | 1067/2495 [00:00<00:00, 10653.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thchs_test.txt\n",
      "2495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2495/2495 [00:00<00:00, 8791.71it/s] \n",
      "100%|██████████| 893/893 [00:00<00:00, 8686.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thchs_dev.txt\n",
      "893\n",
      "trans.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2222/585273 [00:00<00:26, 22218.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585273/585273 [00:17<00:00, 33505.02it/s]\n"
     ]
    }
   ],
   "source": [
    "data_file = 'train.tsv'\n",
    "\n",
    "pny_lst = []\n",
    "han_lst = []\n",
    "with open(data_file,'w+',encoding='utf-8') as final_file:\n",
    "    \n",
    "    for file in file_list[1:]:\n",
    "        print(file)\n",
    "        \n",
    "        with open(file, 'r', encoding='utf8') as f:\n",
    "            data = f.readlines() \n",
    "            print(len(data))\n",
    "            for line in tqdm(data):\n",
    "                wav_file, pny, han = line.split('\\t')               \n",
    "                \n",
    "                pny = pny.split()\n",
    "                han = han.strip()\n",
    "                temp_pny = []\n",
    "                temp_han = []\n",
    "                flag = True\n",
    "                for pny_item in pny:\n",
    "\n",
    "                    if re.match('\\d+', pny_item):\n",
    "                        flag = False\n",
    "                        break\n",
    "                    else:\n",
    "                        temp_pny.append(pny_item)\n",
    "\n",
    "                for han_item in han:\n",
    "                    if re.match('\\d+', han_item):\n",
    "                        flag = False\n",
    "                        break\n",
    "                    else:\n",
    "                        temp_han.append(han_item)\n",
    "\n",
    "                if len(temp_pny)!= len(temp_han):\n",
    "#                     print(pny)\n",
    "#                     print(len(temp_pny),'------',temp_pny)\n",
    "#                     print(han)\n",
    "#                     print(len(temp_han),'------',temp_han)\n",
    "                    flag = False\n",
    "\n",
    "                if flag:\n",
    "                    final_file.write(wav_file+'<SEP>'+' '.join(temp_pny)+'<SEP>'+''.join(temp_han).strip()+'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检测出问题数据：\n",
    "\n",
    "file_list[4] 6  9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANS.txt\n",
      "aidatatang.txt\n",
      "cv.syllable.txt\n"
     ]
    }
   ],
   "source": [
    "for i,item in enumerate(file_list):\n",
    "    if i in [4,6,9]:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANS.txt:\n",
    "1. UtteranceID\tSpeakerID\tTranscription\n",
    "2. 14_3466_20170826171159.wav\t14_3466\t请语言播放小说\n",
    "3. 14_3466_20170826171236.wav\t14_3466\t这里\n",
    "4. 14_3466_20170826171323.wav\t14_3466\t全民唱吧\n",
    "\n",
    "### cv.syllable.txt\n",
    "1. A11_101 qi1 shi2 nian2 dai4 mo4 wo3 wai4 chu1 qiu2 xue2 mu3 qin1 ding1 ning2 wo3 chi1 fan4 yao4 xi4 jiao2 man4 yan4 xue2 xi2 yao4 shen1 zuan1 xi4 yan2 \n",
    "2. A11_119 chen2 yun2 tong2 zhi4 tong2 shi2 yao1 qiu2 gan4 bu5 ren4 zhen1 xue2 xi2 ye4 wu4 jing1 tong1 ye4 wu4 xiang4 yi2 qie4 ye4 wu4 nei4 hang2 ren2 xue2 xi2 \n",
    "\n",
    "### aidatatang.txt\n",
    "1. aidatatang/G0002/session01/T0055G0002S0001.wav\tyi3 hou4 ni3 shi4 nan2 hai2 zi\t以后你是男孩子\n",
    "2. aidatatang/G0002/session01/T0055G0002S0002.wav\tlan2 zhou1 na3 you3 mai3 lu4 hu3 qi4 che1 de\t兰州哪有买路虎汽车的\n",
    "3. aidatatang/G0002/session01/T0055G0002S0004.wav\tkan4 kan4 wo3 de ri4 cheng2 biao3\t看看我的日程表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aidatatang.txt 规范以后\n",
    "237265  -->>  232759  数据减少1.89%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正则表达式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "re.match(pattern, string, flags=0)\n",
    "\n",
    "re.search(pattern, string, flags=0)  # re.search 扫描整个字符串并返回第一个成功的匹配\n",
    "\n",
    "re.sub(pattern, repl, string, count=0, flags=0)# Python 的 re 模块提供了re.sub用于替换字符串中的匹配项。\n",
    "\n",
    "\n",
    "re.compile 函数\n",
    "compile 函数用于编译正则表达式，生成一个正则表达式（ Pattern ）对象，供 match() 和 search() 这两个函数使用。\n",
    "\n",
    "语法格式为：\n",
    "\n",
    ">>>import re\n",
    ">>> pattern = re.compile(r'\\d+')                    # 用于匹配至少一个数字\n",
    ">>> m = pattern.match('one12twothree34four')        # 查找头部，没有匹配\n",
    ">>> print m\n",
    "\n",
    " \n",
    "pattern = re.compile(r'\\d+')   # 查找数字\n",
    "result1 = pattern.findall('runoob 123 google 456')\n",
    "result2 = pattern.findall('run88oob123google456')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单个文件测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1811/7176 [00:00<00:00, 18109.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7176/7176 [00:00<00:00, 18562.03it/s]\n"
     ]
    }
   ],
   "source": [
    "data_file = 'test.tsv'\n",
    "\n",
    "pny_lst = []\n",
    "han_lst = []\n",
    "with open(data_file,'w+',encoding='utf-8') as final_file:\n",
    "    \n",
    "        \n",
    "    with open(file_list[0], 'r', encoding='utf8') as f:\n",
    "        data = f.readlines() \n",
    "        print(len(data))\n",
    "        for line in tqdm(data):\n",
    "            wav_file, pny, han = line.split('\\t')               \n",
    "\n",
    "            pny = pny.split()\n",
    "            han = han.strip()\n",
    "            temp_pny = []\n",
    "            temp_han = []\n",
    "            flag = True\n",
    "            for pny_item in pny:\n",
    "\n",
    "                if re.match('\\d+', pny_item):\n",
    "                    flag = False\n",
    "                    break\n",
    "                else:\n",
    "                    temp_pny.append(pny_item)\n",
    "\n",
    "            for han_item in han:\n",
    "                if re.match('\\d+', han_item):\n",
    "                    flag = False\n",
    "                    break\n",
    "                else:\n",
    "                    temp_han.append(han_item)\n",
    "\n",
    "            if len(temp_pny)!= len(temp_han):\n",
    "                print(pny)\n",
    "                print(len(temp_pny),'------',temp_pny)\n",
    "                print(han)\n",
    "                print(len(temp_han),'------',temp_han)\n",
    "                flag = False\n",
    "\n",
    "            if flag:\n",
    "                final_file.write(wav_file+'<SEP>'+' '.join(temp_pny)+'<SEP>'+''.join(temp_han).strip()+'\\n')\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取文件\n",
    "\n",
    "返回二维拼音 list\n",
    "\n",
    "二维汉字list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    \"\"\"读取文件数据\"\"\"\n",
    "\n",
    "    with open(filename,'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        pny_list = []\n",
    "        han_list = []\n",
    "        for line in lines:\n",
    "            pny_temp=[]\n",
    "        \n",
    "            wav_file, pny, han  = line.split('<SEP>')\n",
    "            han = han.strip()\n",
    "            for pny_item in pny.split(' '):\n",
    "                pny_temp.append(pny_item)\n",
    "                \n",
    "            pny_list.append(pny_temp)\n",
    "            han_list.append([item for item in han])\n",
    "\n",
    "        han_list= [han for han  in han_list]\n",
    "    return pny_list, han_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pny_list,han_list = read_file('train.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['guang3',\n",
       " 'zhou1',\n",
       " 'shi4',\n",
       " 'fang2',\n",
       " 'di4',\n",
       " 'chan3',\n",
       " 'zhong1',\n",
       " 'jie4',\n",
       " 'xie2',\n",
       " 'hui4',\n",
       " 'fen1',\n",
       " 'xi1']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pny_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建词典"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "han_dict_w2id = defaultdict(int)\n",
    "for index, item in enumerate(han_vocab):\n",
    "    han_dict_w2id[item] = index\n",
    "\n",
    "han_dict_id2w = {v: k for k, v in han_dict_w2id.items()}\n",
    "\n",
    "\n",
    "pny_dict_w2id = defaultdict(int)\n",
    "for index, item in enumerate(pny_vocab):\n",
    "    pny_dict_w2id[item] = index\n",
    "\n",
    "pny_dict_id2w = {v: k for k, v in pny_dict_w2id.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def mk_lm_pny_vocab(data):\n",
    "    vocab = ['<PAD>']\n",
    "    shuffle_vocab = []\n",
    "    for line in tqdm(data):\n",
    "        for pny in line:\n",
    "            if pny not in shuffle_vocab:\n",
    "                shuffle_vocab.append(pny)\n",
    "    random.shuffle(shuffle_vocab)\n",
    "    vocab.extend(shuffle_vocab)\n",
    "    pny_dict_w2id = defaultdict(int)\n",
    "    for index, item in enumerate(vocab):\n",
    "        pny_dict_w2id[item] = index\n",
    "\n",
    "    pny_dict_id2w = {v: k for k, v in pny_dict_w2id.items()}\n",
    "\n",
    "    return pny_dict_w2id, pny_dict_id2w\n",
    "\n",
    "\n",
    "def mk_lm_han_vocab(data):\n",
    "    vocab = ['<PAD>']\n",
    "    shuffle_vocab = []\n",
    "    for line in tqdm(data):\n",
    "        # line = ''.join(line.split(' '))\n",
    "        for han in line:\n",
    "            if han not in shuffle_vocab:\n",
    "                shuffle_vocab.append(han)\n",
    "                \n",
    "    random.shuffle(shuffle_vocab)\n",
    "    vocab.extend(shuffle_vocab)\n",
    "    \n",
    "    han_dict_w2id = defaultdict(int)\n",
    "    for index, item in enumerate(vocab):\n",
    "        han_dict_w2id[item] = index\n",
    "\n",
    "    han_dict_id2w = {v: k for k, v in han_dict_w2id.items()}\n",
    "\n",
    "    return han_dict_w2id, han_dict_id2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14326/14326 [00:01<00:00, 9783.38it/s] \n",
      "100%|██████████| 14326/14326 [00:04<00:00, 3161.25it/s]\n"
     ]
    }
   ],
   "source": [
    "pny_dict_w2id, pny_dict_id2w = mk_lm_pny_vocab(pny_list)\n",
    "han_dict_w2id, han_dict_id2w = mk_lm_han_vocab(han_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filename, pny_dict_w2id, han_dict_w2id, seq_len = 100):\n",
    "    \"\"\"将文件转换为id表示\"\"\"\n",
    "    pny_list, han_list = read_file(filename)\n",
    "    pny_id_list = []\n",
    "    han_id_list = []\n",
    "    for i in range(5):\n",
    "        print(pny_list[i])\n",
    "        pny_id_list.append([pny_dict_w2id[x] for x in pny_list[i]]+ [0]*(seq_len-len(pny_list[i])))\n",
    "        han_id_list.append([han_dict_w2id[x] for x in han_list[i]]+ [0]*(seq_len-len(pny_list[i])))\n",
    "        print(pny_id_list[i])\n",
    "    return pny_id_list, han_id_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "a = [1,2,3]\n",
    "b = [4,5,6]\n",
    "random.shuffle(a)\n",
    "random.shuffle(b)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'one_hot:0' shape=(2, 2, 3) dtype=float32>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a=[\n",
    "    [1,2],\n",
    "    [3,4]    \n",
    "]\n",
    "\n",
    "tf.one_hot(a,depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wav_file, pny, han "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regularize TRANS.txt with pny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585273/585273 [02:04<00:00, 4712.89it/s]\n"
     ]
    }
   ],
   "source": [
    "from pypinyin import lazy_pinyin ,Style\n",
    "import re\n",
    "\n",
    "with open('trans.txt','w', encoding='utf-8') as file:\n",
    "    with open( 'TRANS.txt', 'r', encoding='utf8') as f:\n",
    "        data = f.readlines()[1:]\n",
    "        for line in tqdm(data):\n",
    "            wav_file,_ , han = line.split('\\t') \n",
    "            pny = ' '.join(lazy_pinyin(han, style=Style.TONE3))\n",
    "\n",
    "            file.write(wav_file+'\\t'+pny.strip('\\n')+'\\t'+han)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jin1 tian1 tian1 qi4 zhen1 bu4 cuo4 a'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pypinyin import lazy_pinyin,  Style\n",
    "hans = '今天天气真不错啊'\n",
    "a = lazy_pinyin(hans, style=Style.TONE3)\n",
    "s = ' '.join(lazy_pinyin(a, style=Style.TONE3))\n",
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow14",
   "language": "python",
   "name": "tensorflow14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
